---
title: Publications
permalink: pubs
nav_order: 1
last_modified_date: "2025-04-09"
---

# Publications 

## Peer-Reviewed Papers
- [Radar: Fast Long-Context Decoding for Any Transformer](https://arxiv.org/abs/2503.10571) \
  <span style="text-decoration: underline">Yongchang Hao</span>, Mengyao Zhai, Hossein Hajimirsadeghi, Sepidehsadat Hosseini, Frederick Tung \
  *ICLR 2025, Singapore*
- [Exploiting the Index Gradients for Optimization-Based Jailbreaking on Large Language Models](https://arxiv.org/abs/2412.08615)
  Jiahui Li\*, <span style="text-decoration: underline">Yongchang Hao</span>\*, Haoyu Xu, Xing Wang, Yu Hong \
  *COLING 2025, Dubai, U.A.E.*
- [NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks](https://arxiv.org/abs/2410.20650) \
  <span style="text-decoration: underline">Yongchang Hao</span>, Yanshuai Cao, Lili Mou \
  *ENLSP @ NeurIPS 2024, Vancouver, Canada*
- [Flora: Low-Rank Adapters Are Secretly Gradient Compressors](https://arxiv.org/abs/2402.03293) \
  <span style="text-decoration: underline">Yongchang Hao</span>, Yanshuai Cao, Lili Mou \
  *ICML 2024, Vienna, Austria*
- [LLMR: Knowledge Distillation with a Large Language Model-Induced Reward](https://aclanthology.org/2024.lrec-main.932) \
  Dongheng Li, <span style="text-decoration: underline">Yongchang Hao</span>, Lili Mou \
  *COLING 2024, Turin, Italy*
- [An Equal-Size Hard EM Algorithm for Diverse Dialogue Generation](https://arxiv.org/abs/2209.14627) \
  Yuqiao Wen, <span style="text-decoration: underline">Yongchang Hao</span>, Yanshuai Cao, Lili Mou \
  *ICLR 2023, Kigali, Rwanda*
- [Teacher Forcing Recovers Reward Functions for Text Generation](https://arxiv.org/abs/2210.08708) \
  <span style="text-decoration: underline">Yongchang Hao</span>, Yuxin Liu, Lili Mou \
  *NeurIPS 2022, New Orleans, U.S.A.*
- [Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation](https://arxiv.org/abs/2203.08442 ) \
  Wenxuan Wang, Wenxiang Jiao, <span style="text-decoration: underline">Yongchang Hao</span>, Xing Wang, Shuming Shi, Zhaopeng Tu, Michael Lyu \
  *ACL 2022, Dublin, Ireland*
- [Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation](https://arxiv.org/abs/2010.12868) \
  <span style="text-decoration: underline">Yongchang Hao</span>\*, Shilin He\*, Wenxiang Jiao, Zhaopeng Tu, Michael Lyu, Xing Wang \
  *NAACL 2021, Online*

## Preprints
- [ULPT: Prompt Tuning with Ultra-Low-Dimensional Optimization](https://arxiv.org/abs/2502.04501) \
  Zijun Wu, <span style="text-decoration: underline">Yongchang Hao</span>, Lili Mou \
  *ar$\chi$iv 2025*
- [Ginger: An Efficient Curvature Approximation with Linear Complexity for General Neural Networks](https://arxiv.org/abs/2402.03295) \
  <span style="text-decoration: underline">Yongchang Hao</span>, Yanshuai Cao, Lili Mou \
  *ar$\chi$iv 2024*

## Theses
- [Discovering Reward Functions for Language Models](https://era.library.ualberta.ca/items/8ccbb37b-0b6d-4a1a-bc97-269667cdf029) \
  <span style="text-decoration: underline">Yongchang Hao</span> \
  *M.Sc. Thesis, University of Alberta, 2023*
